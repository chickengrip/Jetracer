{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c025afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch2trt import torch2trt\n",
    "\n",
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "from utils import preprocess \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3ff66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CLASSES = ['drive', 'stop']  \n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc15d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road-following model\n",
    "import torchvision \n",
    "\n",
    "follow_model = torchvision.models.resnet18(pretrained=False)\n",
    "follow_model.fc = torch.nn.Linear(512, 2)\n",
    "follow_model = follow_model.to(device).eval().half()\n",
    "follow_model.load_state_dict(torch.load('road_following_model_11_6.pth'))\n",
    "\n",
    "# Classification model\n",
    "classification_model = torchvision.models.resnet18(pretrained=False)\n",
    "classification_model.fc = torch.nn.Linear(512, len(CLASSES))\n",
    "classification_model = classification_model.to(device).eval().half()\n",
    "classification_model.load_state_dict(torch.load('drive_stop_model_10_6.pth'))\n",
    "\n",
    "# TensorRT optimization\n",
    "dummy_input = torch.zeros((1, 3, 224, 224)).to(device).half()\n",
    "follow_model_trt = torch2trt(follow_model, [dummy_input], fp16_mode=True)\n",
    "classification_model_trt = torch2trt(classification_model, [dummy_input], fp16_mode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03fa34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(follow_model_trt.state_dict(), 'follow_model_trt.pth')\n",
    "torch.save(classification_model_trt.state_dict(), 'classification_model_trt_12_06.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb05087",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = CSICamera(width=224, height=224, capture_fps=30)\n",
    "car = NvidiaRacecar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "691b511c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run when already optimized\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "follow_model_trt = TRTModule()\n",
    "classification_model_trt = TRTModule()\n",
    "follow_model_trt.load_state_dict(torch.load('road_following_model_11_6trt.pth'))\n",
    "classification_model_trt.load_state_dict(torch.load('classification_model_trt_12_06.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd088611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(image_tensor):\n",
    "    with torch.no_grad():\n",
    "        output = classification_model_trt(image_tensor)\n",
    "        pred_idx = torch.argmax(output, dim=1).item()\n",
    "        return CLASSES[pred_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d3d515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9977d66b398a403c9104015d6d2ff138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='224', width='224')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import cv2\n",
    "\n",
    "# Create image widget\n",
    "prediction_widget = ipywidgets.Image(format='jpeg', width=camera.width, height=camera.height)\n",
    "display(prediction_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c3c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEERING_GAIN = 0.9\n",
    "STEERING_BIAS = 0.05\n",
    "THROTTLE = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_display(image, output):\n",
    "    # output: numpy array from follow_model_trt\n",
    "    x = float(output[0])\n",
    "    y = float(output[1]) if len(output) > 1 else 0.5  # Use y if your model predicts it, else center\n",
    "\n",
    "    # Convert normalized coordinates to pixel positions\n",
    "    cx = int(camera.width * (x / 2.0 + 0.5))\n",
    "    cy = int(camera.height * (y / 2.0 + 0.5))\n",
    "\n",
    "    img_with_circle = image.copy()\n",
    "    img_with_circle = cv2.circle(img_with_circle, (cx, cy), 8, (255, 0, 0), 3)\n",
    "    prediction_widget.value = bgr8_to_jpeg(img_with_circle)\n",
    "\n",
    "import time\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        raw_image = camera.read()\n",
    "        preprocessed = preprocess(raw_image).half().unsqueeze(0).to(device)\n",
    "\n",
    "        # Run both models on the same preprocessed image\n",
    "        decision = get_classification(preprocessed)\n",
    "        output = follow_model_trt(preprocessed).cpu().numpy().flatten()\n",
    "\n",
    "        if decision == \"drive\":\n",
    "            car.steering = float(output[0]) * STEERING_GAIN + STEERING_BIAS\n",
    "            car.throttle = THROTTLE\n",
    "        else:\n",
    "            # If stopped, set output to default for display\n",
    "            output = np.array([0.0, 0.5])\n",
    "            car.throttle = 0.0\n",
    "            car.steering = 0.0\n",
    "\n",
    "        update_display(raw_image, output)\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    car.throttle = 0\n",
    "    car.steering = 0\n",
    "    print(\"Stopped by user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3657ed7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ce663a8d0f4160afe249b3090025ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='State:', options=('stop', 'live'), value='stop')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "state_widget = widgets.ToggleButtons(options=['stop', 'live'], description='State:', value='stop')\n",
    "display(state_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e19f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from threading import Thread\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "image_widget = ipywidgets.Image()\n",
    "display(image_widget)\n",
    "\n",
    "update_interval = 0.1  # seconds (max 10 FPS)\n",
    "last_update_time = 0\n",
    "\n",
    "def update_image_widget(frame):\n",
    "    global last_update_time\n",
    "    current_time = time.time()\n",
    "    if current_time - last_update_time < update_interval:\n",
    "        return\n",
    "    resized = cv2.resize(frame, (320, 240))  # Resize for smoother display\n",
    "    image_widget.value = bgr8_to_jpeg(resized)\n",
    "    last_update_time = current_time\n",
    "\n",
    "def process_camera():\n",
    "    while True:\n",
    "        frame = camera.read()\n",
    "        # Optionally do inference here\n",
    "        update_image_widget(frame)\n",
    "        time.sleep(0.01)  # avoid CPU overload\n",
    "\n",
    "# Start background processing\n",
    "thread = Thread(target=process_camera)\n",
    "thread.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
